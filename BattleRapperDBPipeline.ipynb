{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4de74a8a-6734-4814-accb-bc714653d272",
   "metadata": {},
   "source": [
    "This project will scrape data from VerseTracker and place it into a data frame. We save the dataframe as a csv and create a tunnel to google big query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415e436f-47f9-4e8b-9309-b9f4f47fa93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from google.cloud import bigquery\n",
    "import pandas_gbq\n",
    "client = bigquery.Client()\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1fe62e-145c-4120-842a-741d582e6a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Extracted: 0\n",
      "Page Extracted: 1\n",
      "Page Extracted: 2\n",
      "Page Extracted: 3\n",
      "Page Extracted: 4\n",
      "Page Extracted: 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m battle_rappers_dict[\u001b[33m\"\u001b[39m\u001b[33mBattle Rapper\u001b[39m\u001b[33m\"\u001b[39m].append(name)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     time.sleep(\u001b[32m10\u001b[39m) \n\u001b[32m     37\u001b[39m     profile_html = requests.get(full_url).text\n\u001b[32m     38\u001b[39m     br_soup = BeautifulSoup(profile_html, \u001b[33m'\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "battle_rappers_dict = {\"Battle Rapper\": [], \"Hometown\": [], \"Bio\": [], \"Total Battles\": [], \"Total Views\": [], \"Average Views\": []}\n",
    "prepend_url = 'https://versetracker.com'\n",
    "\n",
    "while True:  \n",
    "    print(\"Page Extracted:\", index)\n",
    "    \n",
    "    response = requests.get(\n",
    "        f\"https://versetracker.com/all-rappers?name_1=&field_country_tid=21227&field_gender_value=&field_speaks_english_value=&sort_by=field_total_views_value&page={index}\"\n",
    "    )\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    extractedRows = soup.find_all('div', class_=\"views-row\")\n",
    "\n",
    "    if not extractedRows:\n",
    "        print(\"No more pages. Exiting.\")\n",
    "        break\n",
    "\n",
    "    for row in extractedRows:\n",
    "        rapperColumns = row.find_all('div', class_='views-column')\n",
    "\n",
    "        for col in rapperColumns:\n",
    "            name_tag = col.find('div', class_=\"rapper-grid-rapper-name\")\n",
    "\n",
    "            if not name_tag:\n",
    "                continue\n",
    "\n",
    "            name = name_tag.text.strip()\n",
    "            link = col.find('a').get('href')\n",
    "            full_url = prepend_url + link\n",
    "\n",
    "            battle_rappers_dict[\"Battle Rapper\"].append(name)\n",
    "\n",
    "            try:\n",
    "                time.sleep(10) \n",
    "\n",
    "                profile_html = requests.get(full_url).text\n",
    "                br_soup = BeautifulSoup(profile_html, 'html.parser')\n",
    "\n",
    "                hometown = br_soup.find('div', class_=\"rapper-location-info\")\n",
    "                bio = br_soup.find('div', class_=\"rapper-bio\")\n",
    "                stats = br_soup.find('div', class_=\"rapper-stat-block\")\n",
    "\n",
    "                battle_rappers_dict[\"Hometown\"].append(hometown.text.strip() if hometown else \"\")\n",
    "                battle_rappers_dict[\"Bio\"].append(bio.text.strip() if bio else \"\")\n",
    "\n",
    "                if stats:\n",
    "                    total_views = stats.find(\"span\", class_=\"num-font\").text\n",
    "                    total_battles = stats.next_sibling.find('span', class_=\"num-font\").text\n",
    "                    average_views = stats.next_sibling.next_sibling.find('span', class_=\"num-font\").text\n",
    "\n",
    "                    battle_rappers_dict[\"Total Views\"].append(total_views)\n",
    "                    battle_rappers_dict[\"Total Battles\"].append(total_battles)\n",
    "                    battle_rappers_dict[\"Average Views\"].append(average_views)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {name}: {e}\")\n",
    "\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bef660-7d88-404c-bb36-b1957617887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(battle_rappers_dict)\n",
    "df.to_csv('us_battle_rappers_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c4ef9-363f-4dc3-abf6-5868bbb7cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json = os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/reginaldamedee/downloads/battlerapperdb-b2f485aaaacb.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd20c16-e71e-4c26-9831-49fae95a0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'battlerapperdb'\n",
    "table_name = \"battlerapperdb.us_based_battle_rappers_table\"\n",
    "\n",
    "df = pd.read_csv('us_battle_rappers.csv')\n",
    "pandas_gbq.to_gbq(df, table_name, project_id=project_id, if_exists='replace')\n",
    "print(f\"DataFrame successfully uploaded to BigQuery table: {table_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
